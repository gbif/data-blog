blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::preview_site(startup = TRUE)
blogdown:::serve_site()
blogdown:::preview_site(startup = TRUE)
blogdown:::serve_site()
blogdown:::preview_site(startup = TRUE)
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::preview_site(startup = TRUE)
blogdown:::preview_site(startup = TRUE)
blogdown:::preview_site(startup = TRUE)
blogdown:::serve_site()
blogdown:::new_post_addin()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::preview_site(startup = TRUE)
blogdown:::preview_site(startup = TRUE)
blogdown:::preview_site(startup = TRUE)
blogdown:::new_post_addin()
blogdown:::serve_site()
blogdown:::serve_site()
library(dplyr)
library(DT)
# readr::read_tsv("http://download.gbif.org/custom_download/jwaller/gbif_most_wanted_names.tsv")
datatable(iris)
datatable(head(iris), colnames = c('A Better Name' = 'Sepal.Width'))
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::preview_site(startup = TRUE)
blogdown:::preview_site(startup = TRUE)
blogdown:::preview_site(startup = TRUE)
blogdown:::preview_site(startup = TRUE)
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::preview_site(startup = TRUE)
blogdown:::preview_site(startup = TRUE)
blogdown:::new_post_addin()
blogdown:::new_post_addin()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::new_post_addin()
blogdown:::serve_site()
blogdown:::preview_site(startup = TRUE)
blogdown:::serve_site()
blogdown:::serve_site()
servr::daemon_stop(1)
blogdown:::serve_site()
blogdown:::serve_site()
View(map_color)
blogdown:::preview_site(startup = TRUE)
blogdown:::preview_site(startup = TRUE)
blogdown:::preview_site(startup = TRUE)
blogdown:::serve_site()
blogdown:::serve_site()
usethis::edit_r_environ()
# example showing usefulness of GBIF API when combined with purrr
library(dplyr)
library(httr)
library(purrr)
library(jsonlite)
"Trochilidae" %>% # sci name for humming birds
paste0("https://api.gbif.org/v1/species/match?name=",.) %>%
GET() %>%
content() %>%
pluck("usageKey") %>%
paste0("https://api.gbif.org/v1/species/search/?highertaxon_key=",.,"&limit=1000","&rank=SPECIES") %>%
fromJSON() %>%
pluck("results") %>%
pull(speciesKey) %>%
map(~
paste0("https://api.gbif.org/v1/species/",.x,"/vernacularNames") %>%
fromJSON()
) %>%
compact() %>%
map(~ .x %>% pluck("results")) %>%
bind_rows() %>%
select(taxonKey,vernacularName,language) %>%
unique() %>%
glimpse() # all common names for humming birds
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::new_post_addin()
usethis::edit_r_environ()
blogdown:::preview_site(startup = TRUE)
blogdown:::preview_site(startup = TRUE)
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::preview_site(startup = TRUE)
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::preview_site(startup = TRUE)
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::preview_site(startup = TRUE)
blogdown:::preview_site(startup = TRUE)
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
View(sf)
blogdown:::new_post_addin()
blogdown:::new_post_addin()
blogdown:::new_post_addin()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::new_post_addin()
blogdown::install_hugo()
?install.hugo
?install_hugo
blogdown::install_hugo("0.42")
blogdown::install_hugo("0.42",force=TRUE)
blogdown:::new_post_addin()
install.packages("blogdown")
install.packages("blogdown")
install.packages("blogdown")
install.packages("blogdown")
install.packages("blogdown")
install.packages("blogdown")
blogdown:::serve_site()
blogdown:::new_post_addin()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::new_post_addin()
blogdown:::serve_site()
blogdown:::insert_image_addin()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown::stop_server()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::new_post_addin()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::insert_image_addin()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::new_post_addin()
blogdown:::insert_image_addin()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::new_post_addin()
blogdown:::new_post_addin()
library(leaflet)
# need to define new projection. Only this projection will work with custom queries.
epsg4326 <- leafletCRS(crsClass = "L.CRS.EPSG4326", code = "EPSG:4326",
proj4def = "+proj=longlat +datum=WGS84 +no_defs",
resolutions = 2^(10:0),
origin =c(0,0)
)
# create the gbif-geyser style raster layer
projection <- '4326' # must use this projection code for custom maps
style <- 'style=gbif-geyser' # I think any style will work
tileRaster <- paste0('https://tile.gbif.org/',projection,'/omt/{z}/{x}/{y}@1x.png?',style)
# create the data layer with dragonfly data # Note the "adhoc"
prefix <- 'https://api.gbif.org/v2/map/occurrence/adhoc/{z}/{x}/{y}@1x.png?'
# make query
style <- 'style=classic.poly' # style of polygons
taxonKey = 'taxonKey=789' # taxon key of Odonata
country = 'country=JP' # country code of Japan
tilePolygons = paste0(prefix,style,'&',taxonKey,'&',country)
# plot the map
leaflet(options = leafletOptions(crs = epsg4326)) %>%
setView(lng=139.068,lat=36.4910,zoom=03) %>%
addTiles(urlTemplate=tileRaster) %>%
addTiles(urlTemplate=tilePolygons) %>%
addMarkers(139.068,36.4910) # country centroid of Japan
library(leaflet)
prefix = 'https://api.gbif.org/v2/map/occurrence/density/{z}/{x}/{y}@1x.png?'
style = 'style=purpleYellow.point'
tile = paste0(prefix,style)
leaflet() %>%
setView(lng = 20, lat = 20, zoom = 01) %>%
addTiles() %>%
addTiles(urlTemplate=tile)
library(leaflet)
prefix = 'https://api.gbif.org/v2/map/occurrence/density/{z}/{x}/{y}@1x.png?'
style = 'style=purpleYellow.point'
tile = paste0(prefix,style)
leaflet() %>%
setView(lng = 20, lat = 20, zoom = 01) %>%
addTiles() %>%
addTiles(urlTemplate=tile)
library(leaflet)
prefix = 'https://api.gbif.org/v2/map/occurrence/density/{z}/{x}/{y}@1x.png?'
style = 'style=purpleYellow.point'
tile = paste0(prefix,style)
leaflet() %>%
setView(lng = 20, lat = 20, zoom = 01) %>%
addTiles() %>%
addTiles(urlTemplate=tile)
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::new_post_addin()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::new_post_addin()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
here::here()
here
usethis
blogdown:::new_post_addin()
blogdown:::new_post_addin()
blogdown:::insert_image_addin()
blogdown:::serve_site()
blogdown:::insert_image_addin()
blogdown:::insert_image_addin()
blogdown:::insert_image_addin()
blogdown:::insert_image_addin()
blogdown:::insert_image_addin()
blogdown:::serve_site()
install.packages("rgbif")
name_backbone_checklist("dog","dog")
rgbif::name_backbone_checklist("dog","dog")
rgbif::name_backbone_checklist(c("dog","dog")
)
install.packages("rgbif")
install.packages("rgbif")
library(dplyr)
library(readr)
library(rgbif) # for occ_download
# The 60,000 tree names file I downloaded from BGCI
file_url <- "https://data-blog.gbif.org/post/2019-07-11-downloading-long-species-lists-on-gbif_files/global_tree_search_trees_1_3.csv"
# match the names
gbif_taxon_keys <-
readr::read_csv(file_url) %>%
pull("Taxon name") %>% # use fewer names if you want to just test
name_backbone_checklist() %>% # match to backbone
filter(matchtype == "EXACT" & status == "ACCEPTED") %>% # get only accepted and matched names
filter(kingdom == "Plantae") %>% # remove anything that might have matched to a non-plant
pull(usagekey) # get the gbif taxonkeys
library(dplyr)
library(readr)
library(rgbif) # for occ_download
# The 60,000 tree names file I downloaded from BGCI
file_url <- "https://data-blog.gbif.org/post/2019-07-11-downloading-long-species-lists-on-gbif_files/global_tree_search_trees_1_3.csv"
# match the names
gbif_taxon_keys <-
readr::read_csv(file_url) %>%
head(1000) %>% # use only first 1000
pull("Taxon name") %>% # use fewer names if you want to just test
name_backbone_checklist() %>% # match to backbone
filter(matchtype == "EXACT" & status == "ACCEPTED") %>% # get only accepted and matched names
filter(kingdom == "Plantae") %>% # remove anything that might have matched to a non-plant
pull(usagekey) # get the gbif taxonkeys
gbif_taxon_keys
readr::read_csv(file_url) %>%
head(1000) %>% # use only first 1000
pull("Taxon name") %>% # use fewer names if you want to just test
name_backbone_checklist()
blogdown:::serve_site()
occ_download(pred("country", "BW"),format = "SIMPLE_PARQUET")
rgbif::occ_download(pred("country", "BW"),format = "SIMPLE_PARQUET")
rgbif::occ_download(rgbif::pred("country", "BW"),format = "SIMPLE_PARQUET")
occ_download_wait('0137020-210914110416597')
rgbif::occ_download_wait('0137020-210914110416597')
occ_download_get('0137020-210914110416597')
rgbif::occ_download_get('0137020-210914110416597')
library(zip)
blogdown:::serve_site()
rgbif::occ_download(rgbif::pred("country", "BW"),format = "SIMPLE_CSV")
occ_download_wait('0138720-210914110416597')
rgbif::occ_download_wait('0138720-210914110416597')
?zip::unzip()
zip::unzip("C:/Users/ftw712/Desktop/0137020-210914110416597.zip")
zip::unzip("C:/Users/ftw712/Desktop/0137020-210914110416597.zip",exdir="C:/Users/ftw712/Desktop/")
rgbif::occ_download(rgbif::pred("country", "BW"),format = "SIMPLE_CSV")
occ_download_wait('0138730-210914110416597')
rgbif::occ_download_wait('0138730-210914110416597')
occ_download_get('0138730-210914110416597')
rgbif::occ_download_get('0138730-210914110416597')
setwd
setwd("C:/Users/ftw712/Desktop/")
zip::unzip('0137020-210914110416597.zip',exdir="/gbif_parquet")
zip::unzip('0137020-210914110416597.zip',exdir="C:/Users/ftw712/Desktop/gbif_parquet/")
zip::unzip('0137020-210914110416597.zip')
df <- arrow::open_dataset("occurrence.parquet")
df
df %>% glimpse()
library(dplyr)
df %>% glimpse()
library(arrow)
library(dplyr)
local_df <- open_dataset("occurrence.parquet")
local_df %>%
filter(
countrycode == "BW",
kingdom == "Fungi"
) %>%
select(species) %>%
collect()
local_df %>% ncol()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
install.packages("writexl")
blogdown:::insert_image_addin()
blogdown:::insert_image_addin()
blogdown:::insert_image_addin()
blogdown:::serve_site()
blogdown:::insert_image_addin()
blogdown:::serve_site()
blogdown:::insert_image_addin()
blogdown:::insert_image_addin()
blogdown:::insert_image_addin()
blogdown:::insert_image_addin()
blogdown:::serve_site()
blogdown:::serve_site()
library(dplyr)
library(CoordinateCleaner)
name_backbone("Calopteryx xanthostoma")
library(rgbif)
name_backbone()
name_backbone("Calopteryx xanthostoma")
name_backbone("Calopteryx xanthostoma")$usageKey
gbif_download <- occ_download(
pred("taxonKey", taxonkey),
pred("hasCoordinate", TRUE),
pred("hasGeospatialIssue", FALSE),
format = "SIMPLE_CSV"
) %>%
occ_download_wait()
taxonkey <- name_backbone("Calopteryx xanthostoma")$usageKey
gbif_download <- occ_download(
pred("taxonKey", taxonkey),
pred("hasCoordinate", TRUE),
pred("hasGeospatialIssue", FALSE),
format = "SIMPLE_CSV"
) %>%
occ_download_wait()
gbif_download
gbif_download %>%unclass()
gbif_download %>%
occ_download_wait() %>%
occ_download_get(.$key) %>%
occ_download_import() %>%
glimpse()
gbif_download <- occ_download(
pred("taxonKey", taxonkey),
pred("hasCoordinate", TRUE),
pred("hasGeospatialIssue", FALSE),
format = "SIMPLE_CSV"
)
occ_download_wait()
gbif_download <- occ_download(
pred("taxonKey", taxonkey),
pred("hasCoordinate", TRUE),
pred("hasGeospatialIssue", FALSE),
format = "SIMPLE_CSV"
)
occ_download_wait(gbif_download)
occ_download_get(gbif_download) %>%
occ_download_import() %>%
glimpse()
occ_download_get(gbif_download) %>%
occ_download_import() %>%
glimpse() %>%
select(establishmentMeans) %>%
unique()
occ_download_get(gbif_download) %>%
occ_download_import() %>%
glimpse()
occ_download_get(gbif_download) %>%
occ_download_import() %>%
filter(occurrencestatus  == "PRESENT") %>%
filter(!basisofrecord %in% c("FOSSIL_SPECIMEN","LIVING_SPECIMEN")) %>%
filter(year >= 1900) %>%
filter(coordinateprecision < 0.01 | is.na(coordinateprecision)) %>%
filter(coordinateuncertaintyinmeters < 10000 | is.na(coordinateuncertaintyinmeters)) %>%
filter(!coordinateuncertaintyinmeters %in% c(301,3036,999,9999)) %>%
filter(!decimallatitude == 0 | !decimallongitude == 0) %>%
cc_cen(buffer = 2000) %>% # remove country centroids within 2km
cc_cap(buffer = 2000) %>% # remove capitals centroids within 2km
cc_inst(buffer = 2000) %>% # remove zoo and herbaria within 2km
cc_sea() %>% # remove from ocean
distinct(decimallongitude,decimallatitude,specieskey,datasetkey, .keep_all = TRUE) %>%
glimpse() # look at results of pipeline
gbif_download %>%
occ_download_get() %>%
occ_download_import() %>%
filter(occurrencestatus  == "PRESENT") %>%
filter(!basisofrecord %in% c("FOSSIL_SPECIMEN","LIVING_SPECIMEN")) %>%
filter(year >= 1900) %>%
filter(coordinateprecision < 0.01 | is.na(coordinateprecision)) %>%
filter(coordinateuncertaintyinmeters < 10000 | is.na(coordinateuncertaintyinmeters)) %>%
filter(!coordinateuncertaintyinmeters %in% c(301,3036,999,9999)) %>%
filter(!decimallatitude == 0 | !decimallongitude == 0) %>%
cc_cen(buffer = 2000) %>% # remove country centroids within 2km
cc_cap(buffer = 2000) %>% # remove capitals centroids within 2km
cc_inst(buffer = 2000) %>% # remove zoo and herbaria within 2km
cc_sea() %>% # remove from ocean
distinct(decimallongitude,decimallatitude,specieskey,datasetkey, .keep_all = TRUE) %>%
glimpse() # look at results of pipeline
gbif_download %>%
occ_download_get() %>%
occ_download_import() %>%
glimpse()
gbif_download %>%
occ_download_get() %>%
occ_download_import() %>%
setNames(tolower(names(.))) %>% # set lowercase column names to work with CoordinateCleaner
filter(occurrencestatus  == "PRESENT") %>%
filter(!basisofrecord %in% c("FOSSIL_SPECIMEN","LIVING_SPECIMEN")) %>%
filter(year >= 1900) %>%
filter(coordinateprecision < 0.01 | is.na(coordinateprecision)) %>%
filter(coordinateuncertaintyinmeters < 10000 | is.na(coordinateuncertaintyinmeters)) %>%
filter(!coordinateuncertaintyinmeters %in% c(301,3036,999,9999)) %>%
filter(!decimallatitude == 0 | !decimallongitude == 0) %>%
cc_cen(buffer = 2000) %>% # remove country centroids within 2km
cc_cap(buffer = 2000) %>% # remove capitals centroids within 2km
cc_inst(buffer = 2000) %>% # remove zoo and herbaria within 2km
cc_sea() %>% # remove from ocean
distinct(decimallongitude,decimallatitude,specieskey,datasetkey, .keep_all = TRUE) %>%
glimpse() # look at results of pipeline
Here we see that GBIF is probably missing many names from **Coleoptera** (Beetles) and **Lepidoptera** (Butterflies/Moths). There are also many potential missing names within birds, but this might be due to the large number of occurrence records we get from this group (Passeriformes).
blogdown:::insert_image_addin()
blogdown:::insert_image_addin()
blogdown:::serve_site()
install.packages("blogdown")
blogdown:::serve_site()
blogdown::install_hugo()
blogdown:::serve_site()
?blogdown::install_hugo
?blogdown::install_hugo(version="0.91.2")
blogdown::install_hugo(version="0.91.2")
usethis::edit_r_profile()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::new_post_addin()
blogdown:::serve_site()
blogdown:::insert_image_addin()
blogdown:::insert_image_addin()
blogdown:::insert_image_addin()
blogdown:::insert_image_addin()
blogdown:::insert_image_addin()
blogdown:::insert_image_addin()
blogdown:::insert_image_addin()
blogdown:::insert_image_addin()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::insert_image_addin()
install.packages("blogdown")
install.packages("blogdown")
install.packages("blogdown")
install.packages("blogdown")
install.packages("blogdown")
blogdown:::serve_site()
blogdown::install_hugo("0.91.2")
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::new_post_addin()
install.packages("xfun")
install.packages("xfun")
install.packages("xfun")
install.packages("xfun")
blogdown:::serve_site()
blogdown:::new_post_addin()
